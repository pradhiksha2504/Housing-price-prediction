# -*- coding: utf-8 -*-
"""Housingdataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sNcNx6hSHbtg1cdHZVR3aJ2_JUM0XsFi
"""

import numpy as np
import pandas as pd
import seaborn as sb
import matplotlib.pyplot as plt
import tensorflow as tf

from google.colab import drive
drive.mount('/content/drive')

df=pd.read_csv("/content/drive/MyDrive/HousingData.csv")

df

"""DESCRIPTIVE ANANLYSIS

"""

df.info()

df.size

df.shape

df.describe()

df.isnull().sum()

df.isnull().sum().sum()

sb.heatmap(df.isnull())

df.dropna(inplace=True)

df.isnull().sum().sum()

sb.heatmap(df.isnull())

df.info()

df.describe()

df.shape

df.size

df

plt.subplots(figsize=(13, 10))
sb.heatmap(df.corr(),annot=True)

cat_col = ['CHAS','RAD']
num_col = ['CRIM','ZN','INDUS','NOX','RM','AGE','DIS','TAX','PTRATIO','B','LSTAT']
cols = cat_col + num_col

cols

"""NORMALIZATION

"""

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
y = df['MEDV']
df = df.drop("MEDV", axis=1)

num_col

Scaler = StandardScaler()
scaled_cols = Scaler.fit_transform(df[num_col])

scaled_cols = pd.DataFrame(scaled_cols)
scaled_cols.columns = num_col
scaled_cols.head()

scaled_cols.isnull().sum()

scaled_col = Scaler.fit_transform(df[cat_col])

scaled_col = pd.DataFrame(scaled_col)
scaled_col.columns = cat_col
scaled_col.head()

scaled_col.isnull().sum()

df2 = (scaled_col).join(scaled_cols)
df2.head()

df2.isnull().sum()

from sklearn.model_selection import train_test_split
(X_train, X_test, y_train, y_test) = train_test_split(df2,y,test_size=0.1)

y_test.shape

X_test.shape

X_train

from keras import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Dense(13, activation='relu'))
model.add(Dense(50, activation='relu'))
model.add(Dense(100, activation='relu'))
model.add(Dense(50, activation='relu'))
model.add(Dense(1))

model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001), loss='mean_squared_error')

model.fit(X_train, y_train, epochs=50)

from sklearn.metrics import mean_squared_error
# Make predictions on the test set
predictions = model.predict(X_test)

# Calculate the mean squared error
mse = mean_squared_error(y_test, predictions)

print(mse)

from sklearn.metrics import mean_squared_error
# Make predictions on the test set
predictions = model.predict(X_test)

# Calculate the mean absolute error
mae = mean_squared_error(y_test, predictions)

print(mae)